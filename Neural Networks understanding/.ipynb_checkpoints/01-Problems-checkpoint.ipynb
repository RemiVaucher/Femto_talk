{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of **problems** we may need to solve:\n",
    "\n",
    "- **minimization**: $\\arg \\min_x f(x)$ for $f: \\mathbb{R}^N \\to \\mathbb{R}$\n",
    "- **interpolation**: given a function $f$, finding the function $g$ in a given space such that $f(x) = g(x)$ for $x$ in a given set (interpolation points) and such that $g$ \"best\" matches $f$ (Example: polynomial interpolation, spline,...)\n",
    "- **solving a PDE**: finding $f$ in a given space such that $\\mathcal{S}(x, f, \\nabla\\!f, \\nabla^2\\!f, \\dots) = 0$\n",
    "- **classification**: given inputs (images, physical quantities,...), assign a class to the input:\n",
    "  - is that a kitten?!!\n",
    "  - what number is written in that image?\n",
    "  - red/blue points in 2D\n",
    "- **regression**: finding a function $g$ in a given space that \"best\" matches a given set of (input, output) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red & blue dots\n",
    "\n",
    "A first example of classification problem is **splitting the space** $\\mathbb{R}^2$ in red and blue zones based on a finite sampling with a possible noise (wrong class or wrong position).\n",
    "\n",
    "We first use Scikit-Learn to generate some sampling of following splitting:\n",
    "1. two moon-shaped zones,\n",
    "2. two nested circles,\n",
    "3. the plan splitting by a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "# Sampling parameters\n",
    "n_samples = 100\n",
    "sigma = 0.3 # Noise\n",
    "\n",
    "# Sampling shape\n",
    "X_train, y_train = make_moons(n_samples=n_samples, noise=sigma, random_state=0)\n",
    "#X_train, y_train = make_circles(n_samples=n_samples, noise=sigma, factor=0.5, random_state=0)\n",
    "#X_train, y_train = make_classification(n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red/Blue colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# Plot the training points\n",
    "plt.figure()\n",
    "plt.title(\"Input data\")\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One algorithm of classification is the **K-Nearest Neighbors**: for a given $(x,y)$ point, we found the $K$ nearest points (for a given norm) from the training dataset and we assign the most present class from these $K$ points to $(x,y)$.\n",
    "\n",
    "$K$ is called a **hyper-parameter** of the model and choosing it appropriately is part of the problem. For example, increasing $K$ makes this algorithm more stable to outliers but a too high value can make it less efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norm = lambda x: np.linalg.norm(x, ord=1, axis=-1)\n",
    "l2_norm = lambda x: np.linalg.norm(x, ord=2, axis=-1)\n",
    "linf_norm = lambda x: np.linalg.norm(x, ord=np.inf, axis=-1)\n",
    "\n",
    "# K-nearest neighbors\n",
    "# Take a look at https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "# for real applications.\n",
    "def kNN_predict(X_train, y_train, X_test, K=1, norm=l2_norm):\n",
    "    num_test = X_test.shape[0]\n",
    "    y_pred = np.empty(num_test, dtype=y_train.dtype)\n",
    "    \n",
    "    for i in range(num_test):\n",
    "        # Distance from the current test point to the entire training set\n",
    "        dist = norm(X_train - X_test[i, :])\n",
    "        \n",
    "        # Split the distance array by the K elements with lower value\n",
    "        k_partition = np.argpartition(dist, K)\n",
    "        \n",
    "        # Get the classes of the K nearest elements\n",
    "        nearest_class = y_train[k_partition[:K]]\n",
    "        \n",
    "        # Get the most common class\n",
    "        knn, knn_counts = np.unique(nearest_class, return_counts=True)\n",
    "        y_pred[i] = knn[np.argmax(knn_counts)]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test dataset** is a fine Cartesian grid of the space in order to visualize the red and blue domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test dataset as a uniform sampling of the space\n",
    "\n",
    "# Space step\n",
    "h = 0.02\n",
    "\n",
    "# Domain bounds\n",
    "x_min, x_max = X_train[:, 0].min() - .5, X_train[:, 0].max() + .5\n",
    "y_min, y_max = X_train[:, 1].min() - .5, X_train[:, 1].max() + .5\n",
    "\n",
    "# Points list\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "points = np.empty((xx.size, 2))\n",
    "points[:, 0] = xx.ravel()\n",
    "points[:, 1] = yy.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Testing several K\n",
    "for K in [1, 5, 10, 50]:\n",
    "    Z = kNN_predict(X_train, y_train, points, K)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "    plt.contourf(xx, yy, Z.reshape(xx.shape), cmap=cm_bright, alpha=0.5)\n",
    "    plt.title(f\"K = {K}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification\n",
    "\n",
    "Another example is the **image classification**.\n",
    "The MNIST dataset contains images of handwritten digits with associated label (the corresponding digit).\n",
    "\n",
    "The dataset is splitted in a **training** part and a **testing** part. The goal is to recognize the digits from the **testing** part given the **training** images and their labels.\n",
    "\n",
    "The first step is to download the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-37ccc1d1d030>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# We use tensorflow_datasets to download the MNIST dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# We use tensorflow_datasets to download the MNIST dataset\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_trainset, mnist_testset), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accelerate the training, we only choose a subset of the training and testing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "ntrain = 12000\n",
    "train_images = np.empty((ntrain, *ds_info.features['image'].shape))\n",
    "train_labels = np.empty(ntrain, dtype=int)\n",
    "for i, (image, label) in mnist_trainset.shuffle(60000).take(ntrain).enumerate():\n",
    "    train_images[i] = image\n",
    "    train_labels[i] = label\n",
    "\n",
    "# Testing dataset\n",
    "ntest = 2000\n",
    "test_images = np.empty((ntest, *ds_info.features['image'].shape))\n",
    "test_labels = np.empty(ntest, dtype=int)\n",
    "for i, (image, label) in mnist_testset.shuffle(10000).take(ntest).enumerate():\n",
    "    test_images[i] = image\n",
    "    test_labels[i] = label\n",
    "\n",
    "print(f\"Number of images in the train set: {ntrain}. Size of images: {train_images[0].shape}\")\n",
    "print(f\"Number of images in the test set: {ntest}. Size of images: {test_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images from the training dataset\n",
    "def show_mnist(nrow, ncol, data, targets):\n",
    "    count = 0\n",
    "    plt.figure()\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            ax = plt.subplot(nrow, ncol, count + 1)\n",
    "            ax.imshow(data[count, ...], cmap='Greys')\n",
    "            ax.tick_params(axis='both', which='both', bottom=False, top=False, labelbottom=False, right=False, left=False, labelleft=False)\n",
    "            ax.set_title(f\"This is a {targets[count]}\")\n",
    "            count += 1\n",
    "            \n",
    "nrow = 2\n",
    "ncol = 5\n",
    "indices = np.random.choice(ntrain, nrow * ncol, replace=False)\n",
    "show_mnist(2, 5, train_images[indices], train_labels[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the \"red & blue dots\" problem, we propose to use the **K-nearest neighbors** method to recognize the digits.\n",
    "\n",
    "Each image is seen as a matrix of values within $[0, 1]$ corresponding to its luminosity (0 for white, 1 for black).\n",
    "The distance between two images is thus related to the **difference of luminosity for each pixel**.\n",
    "\n",
    "One consequence is that, depending on the chosen distance, the distance between one image and a shifted version of itself can be very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using the K-nearest Neighbors method\n",
    "test_predictions = kNN_predict(\n",
    "    train_images.reshape((ntrain, -1)), # Flattening the images as a 1D vector\n",
    "    train_labels, \n",
    "    test_images.reshape((ntest, -1)),\n",
    "    K=5,\n",
    "    norm=l2_norm,\n",
    ")\n",
    "                \n",
    "\n",
    "print(f\"Accuracy of predictions: {np.mean(np.equal(test_predictions, test_labels)) * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing some predictions\n",
    "nrow = 2\n",
    "ncol = 5\n",
    "\n",
    "# indices = np.arange(test_labels.size)\n",
    "indices = np.argwhere(np.not_equal(test_predictions, test_labels)).ravel() # To show only wrong predictions\n",
    "\n",
    "show_indices = np.random.choice(indices, min(indices.size, nrow * ncol), replace=False)\n",
    "show_mnist(max(1, show_indices.size // 5), min(show_indices.size, 5), test_images[show_indices], test_predictions[show_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the right answers\n",
    "show_mnist(max(1, show_indices.size // 5), min(show_indices.size, 5), test_images[show_indices], test_labels[show_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "We consider a point cloud $(x_k, y_k)$ for $1 \\leq i \\leq K$. The goal is to fit this point cloud by a function that can be written as a linear combination of $N$ base functions (denoted by $\\varphi_n$):\n",
    "$$\n",
    "f(x) = \\sum_{n=1}^N a_n \\varphi_n(x) \\ .\n",
    "$$\n",
    "This can be done by minimizing the following function:\n",
    "$$\n",
    "J(\\mathbf{a}) = \\frac{1}{2 K} \\sum_{k=1}^K \\left(f(x_k) - y_k\\right)^2 \\ .\n",
    "$$\n",
    "Deriving with respect to the coefficient $a_i$:\n",
    "$$\n",
    "\\partial_{a_i} J(\\mathbf{a}) = \\frac{1}{K} \\sum_{k=1}^K \\varphi_i(x_k) \\left(f(x_k) - y_k\\right) \\ .\n",
    "$$\n",
    "A zero of the gradient of $J$ is given by the solution of the linear system:\n",
    "$$\n",
    "\\sum_{j=1}^N \\left( \\frac{1}{K} \\sum_{k=1}^K \\varphi_i(x_k) \\varphi_j(x_k) \\right) a_j = \\frac{1}{K} \\sum_{k=1}^K y_k \\varphi_i(x_k)\n",
    "\\quad \\forall i \\in \\{ 1, \\dots, N \\} \\ .\n",
    "$$\n",
    "\n",
    "For example:\n",
    "- $\\varphi_n(x) = x^n$, fits the point cloud by a polynomial\n",
    "- Given a uniformly spaced discretization of a segment $[a, b]$ with $N$ nodes $\\theta_i$, if $\\varphi_n(x)$ is the hat function centered at $\\theta_n$, $f$ is a piecewise affine function with $N$ points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underlying function\n",
    "We first define the **underlying function** used to generate the point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions used to generate a point cloud\n",
    "\n",
    "# Polynom of given order with random roots, or given roots\n",
    "def poly_from_roots(order=6, roots=None):\n",
    "    if roots is None:\n",
    "        roots = np.random.uniform(-2, 2, order)\n",
    "    P = np.poly1d(roots, r=True, variable='X')\n",
    "    return P\n",
    "\n",
    "# Hat function\n",
    "def hat(center=0, width=1, height=1):\n",
    "    return lambda x: height * np.maximum(1 - 2 * np.abs(x - center) / width, 0)\n",
    "\n",
    "# Rectangular shape with given center, width and height\n",
    "def rectangular(center=0, width=1, height=1):\n",
    "    return lambda x: height * (np.abs(x - center) <= width/2).astype(x.dtype)\n",
    "\n",
    "# Sinusoidal\n",
    "def sine(freq=1, phase=0, height=1):\n",
    "    return lambda x: height * np.sin(2 * np.pi * freq * x + phase)\n",
    "\n",
    "# Sawtooth\n",
    "def sawtooth(freq=1, phase=0, height=1):\n",
    "    return lambda x: (x % (1/freq))\n",
    "\n",
    "# Gauss function\n",
    "def gauss(mean=0, sigma=1):\n",
    "    return lambda x: np.exp(-0.5 * ((x - mean)/sigma)**2)\n",
    "\n",
    "# Sinusoidal and a line\n",
    "def sinandline(freq=1, phase=0, height=1, slope=0.5):\n",
    "    freq = 2*freq\n",
    "    transition_point = (np.arccos(slope / (2*np.pi*freq*height)) - phase) / (2*np.pi*freq)\n",
    "    sine_part = sine(freq, phase, height)\n",
    "    line_part = lambda x: slope * (x - transition_point) + sine_part(transition_point)\n",
    "\n",
    "    def fn(x):\n",
    "        x_mod = (x - transition_point + 1/freq)  % (2 / freq)\n",
    "        x_div = (x - transition_point + 1/freq) // (2 / freq)\n",
    "        shift = x_div * slope / freq\n",
    "        return np.where(x_mod <= 1/freq,\n",
    "                        sine_part(x) + shift,\n",
    "                        line_part(x) - shift)\n",
    "    \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain limits\n",
    "xleft, xright = -1, 1\n",
    "\n",
    "# Number of points for plots\n",
    "npointplot = 1001\n",
    "\n",
    "f = poly_from_roots()\n",
    "#f = hat()\n",
    "#f = rectangular()\n",
    "#f = sine()\n",
    "#f = sawtooth()\n",
    "#f = gauss(sigma=0.1)\n",
    "#f = sinandline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the function\n",
    "xx = np.linspace(xleft, xright, npointplot)\n",
    "plt.figure()\n",
    "plt.plot(xx, f(xx), 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point cloud\n",
    "\n",
    "Then, we generate the associated **point cloud** with a given **noise** level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of points in the point cloud\n",
    "npointcloud = 50\n",
    "\n",
    "# Noise for the point cloud\n",
    "sigma = 0.1\n",
    "\n",
    "# Domain discretization\n",
    "x = np.linspace(xleft, xright, npointcloud)\n",
    "#x = np.random.uniform(xleft, xright, npointcloud)\n",
    "\n",
    "# Generating the point cloud and plotting it\n",
    "y = f(x)\n",
    "y += sigma * np.random.randn(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the function and the point cloud\n",
    "xx = np.linspace(xleft, xright, npointplot)\n",
    "plt.figure()\n",
    "plt.plot(xx, f(xx), 'r--', alpha=0.6)\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis functions\n",
    "\n",
    "We define the basis functions used to fit the points $(x_k, y_k)$.\n",
    "\n",
    "**Note:** each base functions generator return $\\phi(x,i)$ and eventually the points associated to the basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial basis\n",
    "def poly_basis():\n",
    "    def func(x, i):\n",
    "        return x**i\n",
    "        #return scipy.special.eval_legendre(i, x)\n",
    "    return func, None\n",
    "\n",
    "# Hat functions centered on cartesian grid\n",
    "def hat_basis(N, a, b):\n",
    "    xx, dxx = np.linspace(a, b, N, retstep=True)\n",
    "    def func(x, i):\n",
    "        return hat(center=xx[i], width=2*dxx)(x)\n",
    "    return func, xx\n",
    "\n",
    "# Fourier basis\n",
    "def fourier_basis(a, b):\n",
    "    def func(x, i):\n",
    "        if i & 1:\n",
    "            return np.sin(np.pi * (i + 1) * x / np.abs(b - a))\n",
    "        else:\n",
    "            return np.cos(np.pi * i * x / np.abs(b - a))\n",
    "    return func, None\n",
    "\n",
    "# Rectangular function centered on cartesian grid\n",
    "def rect_basis(N, a, b):\n",
    "    xx, dxx = np.linspace(a, b, N, retstep=True)\n",
    "    def func(x, i):\n",
    "        return rectangular(center=xx[i], width=dxx)(x)\n",
    "    return func, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of basis functions\n",
    "N = 11\n",
    "\n",
    "# Choice of the function used to fit the point cloud\n",
    "# xphi are the discretisation points, if any, None otherwise.\n",
    "phi, xphi = poly_basis()\n",
    "#phi, xphi = hat_basis(N, xleft, xright)\n",
    "#phi, xphi = fourier_basis(xleft, xright)\n",
    "#phi, xphi = rect_basis(N, xleft, xright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of the basis functions\n",
    "xx = np.linspace(xleft, xright, 10*npointplot)\n",
    "plt.figure()\n",
    "for i in range(N):\n",
    "    plt.plot(xx, phi(xx, i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System build and solve\n",
    "\n",
    "We build the linear system and solve it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building matrix\n",
    "M = np.empty((N, N))\n",
    "b = np.empty(N)\n",
    "for i in range(N):\n",
    "    phi_i = phi(x, i)\n",
    "    b[i] = np.mean(y * phi_i)\n",
    "    \n",
    "    for j in range(i, N):\n",
    "        M[i, j] = np.mean(phi(x, j) * phi_i)\n",
    "        M[j, i] = M[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solves the linear system\n",
    "a = np.linalg.solve(M, b)\n",
    "#a = np.linalg.lstsq(M, b, rcond=None)[0] # Use this if the system is ill-formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting function (linear combination of base functions)\n",
    "def fit_func(x):\n",
    "    y = np.zeros(x.shape)\n",
    "    for i in range(N):\n",
    "        y += a[i] * phi(x, i)\n",
    "    return y\n",
    "\n",
    "# Plots the results\n",
    "cloud_max = np.amax(y)\n",
    "cloud_min = np.amin(y)\n",
    "margin = 0.25 * (cloud_max - cloud_min)\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "plt.scatter(x, y, label=\"point cloud\")\n",
    "plt.plot(xx, fit_func(xx), 'r', label=\"fitting function\")\n",
    "plt.plot(xx, f(xx), 'r--', alpha=0.6, label='reference function')\n",
    "\n",
    "if xphi is not None:\n",
    "    plt.scatter(xphi, a, s=200, c=\"limegreen\", marker=\"x\", label=\"discretization points of basis functions\")\n",
    "\n",
    "plt.ylim(cloud_min - margin, cloud_max + margin)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.08), ncol=3, fancybox=True, shadow=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.linalg.norm(fit_func(xx) - f(xx))\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
